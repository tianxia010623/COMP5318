{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP5318 Assignment 1: Rice Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Group number: ...\n",
    "##### Student 1 SID: ...\n",
    "##### Student 2 SID: ...  \n",
    "##### Student 3 SID: ... \n",
    "##### Student 4 SID: ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all libraries\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore future warnings\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the rice dataset: rice-final2.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy import signal\n",
    "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "df = pd.read_csv('rice-final2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimiter</th>\n",
       "      <th>Major_Axis_Length</th>\n",
       "      <th>Minor_Axis_Length</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>Convex_Area</th>\n",
       "      <th>Extent</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4628</td>\n",
       "      <td>0.5406</td>\n",
       "      <td>0.5113</td>\n",
       "      <td>0.4803</td>\n",
       "      <td>0.7380</td>\n",
       "      <td>0.4699</td>\n",
       "      <td>0.1196</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4900</td>\n",
       "      <td>0.5547</td>\n",
       "      <td>0.5266</td>\n",
       "      <td>0.5018</td>\n",
       "      <td>0.7319</td>\n",
       "      <td>0.4926</td>\n",
       "      <td>0.8030</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6109</td>\n",
       "      <td>0.6847</td>\n",
       "      <td>0.6707</td>\n",
       "      <td>0.5409</td>\n",
       "      <td>0.8032</td>\n",
       "      <td>0.6253</td>\n",
       "      <td>0.1185</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6466</td>\n",
       "      <td>0.6930</td>\n",
       "      <td>0.6677</td>\n",
       "      <td>0.5961</td>\n",
       "      <td>0.7601</td>\n",
       "      <td>0.6467</td>\n",
       "      <td>0.2669</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6712</td>\n",
       "      <td>0.6233</td>\n",
       "      <td>0.4755</td>\n",
       "      <td>0.8293</td>\n",
       "      <td>0.3721</td>\n",
       "      <td>0.6803</td>\n",
       "      <td>0.4211</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Area  Perimiter  Major_Axis_Length  Minor_Axis_Length  Eccentricity  \\\n",
       "0  0.4628     0.5406             0.5113             0.4803        0.7380   \n",
       "1  0.4900     0.5547             0.5266             0.5018        0.7319   \n",
       "2  0.6109     0.6847             0.6707             0.5409        0.8032   \n",
       "3  0.6466     0.6930             0.6677             0.5961        0.7601   \n",
       "4  0.6712     0.6233             0.4755             0.8293        0.3721   \n",
       "\n",
       "   Convex_Area  Extent class  \n",
       "0       0.4699  0.1196     1  \n",
       "1       0.4926  0.8030     1  \n",
       "2       0.6253  0.1185     0  \n",
       "3       0.6467  0.2669     0  \n",
       "4       0.6803  0.4211     1  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pre-process dataset\n",
    "imputer =SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "df = df.dropna(axis=1, how='all')\n",
    "df = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "scaler = MinMaxScaler()\n",
    "df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "df1 = pd.read_csv('rice-final2.csv', usecols=['class'])\n",
    "df1['class'] = df1['class'].replace({\"class1\": \"0\", \"class2\": \"1\"})\n",
    "df = pd.concat([df, df1], axis=1)\n",
    "df.loc[:, df.columns != 'class'] = df.loc[:, df.columns != 'class'].round(4)\n",
    "df.to_csv(\"processed_rice.csv\", index=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print first ten rows of pre-processed dataset to 4 decimal places as per assignment spec\n",
    "# A function is provided to assist\n",
    "\n",
    "def print_data(X, y, n_rows=10):\n",
    "    \"\"\"Takes a numpy data array and target and prints the first ten rows.\n",
    "    \n",
    "    Arguments:\n",
    "        X: numpy array of shape (n_examples, n_features)\n",
    "        y: numpy array of shape (n_examples)\n",
    "        n_rows: numpy of rows to print\n",
    "    \"\"\"\n",
    "    for example_num in range(n_rows):\n",
    "        for feature in X[example_num]:\n",
    "            print(\"{:.4f}\".format(feature), end=\",\")\n",
    "\n",
    "        if example_num == len(X)-1:\n",
    "            print(y[example_num],end=\"\")\n",
    "        else:\n",
    "            print(y[example_num])\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4628,0.5406,0.5113,0.4803,0.7380,0.4699,0.1196,1\n",
      "0.4900,0.5547,0.5266,0.5018,0.7319,0.4926,0.8030,1\n",
      "0.6109,0.6847,0.6707,0.5409,0.8032,0.6253,0.1185,0\n",
      "0.6466,0.6930,0.6677,0.5961,0.7601,0.6467,0.2669,0\n",
      "0.6712,0.6233,0.4755,0.8293,0.3721,0.6803,0.4211,1\n",
      "0.2634,0.2932,0.2414,0.4127,0.5521,0.2752,0.2825,1\n",
      "0.8175,0.9501,0.9515,0.5925,0.9245,0.8162,0.0000,0\n",
      "0.3174,0.3588,0.3601,0.3908,0.6921,0.3261,0.8510,1\n",
      "0.3130,0.3050,0.2150,0.5189,0.3974,0.3159,0.4570,1\n",
      "0.5120,0.5237,0.4409,0.6235,0.5460,0.5111,0.3155,1\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['class']).values\n",
    "y = df['class'].values\n",
    "print_data(X,y,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Cross-validation without parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting the 10 fold stratified cross-validation\n",
    "cvKFold=StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "# The stratified folds from cvKFold should be provided to the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "def logregClassifier(X, y):\n",
    "\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "    clf = LogisticRegression(random_state=0, max_iter=1000)\n",
    "    scores = cross_val_score(clf, X, y, cv=cvKFold)\n",
    "   \n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naïve Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "\n",
    "def nbClassifier(X, y):\n",
    "    model = GaussianNB()\n",
    "    scores = cross_val_score(model, X, y, cv=cvKFold)\n",
    "    \n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "def dtClassifier(X, y):\n",
    "    clf = DecisionTreeClassifier(criterion=\"entropy\", random_state=0)\n",
    "    scores = cross_val_score(clf, X, y, cv=cvKFold)\n",
    "    \n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensembles: Bagging, Ada Boost and Gradient Boosting\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "def bagDTClassifier(X, y, n_estimators, max_samples, max_depth):\n",
    "    base_dt = DecisionTreeClassifier(criterion=\"entropy\", max_depth=max_depth, random_state=0)\n",
    "    bagging = BaggingClassifier(\n",
    "        estimator=base_dt,\n",
    "        n_estimators=n_estimators,\n",
    "        max_samples=max_samples,\n",
    "        random_state=0\n",
    "    )\n",
    "    scores = cross_val_score(bagging, X, y, cv=cvKFold)\n",
    "    return scores.mean()\n",
    "\n",
    "def adaDTClassifier(X, y, n_estimators, learning_rate, max_depth):\n",
    "    base_dt = DecisionTreeClassifier(criterion=\"entropy\", max_depth=max_depth, random_state=0)\n",
    "    ada = AdaBoostClassifier(\n",
    "        estimator=base_dt,\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        random_state=0\n",
    "    )\n",
    "    scores = cross_val_score(ada, X, y, cv=cvKFold)\n",
    "    return scores.mean()\n",
    "\n",
    "def gbClassifier(X, y, n_estimators, learning_rate):\n",
    "    gb = GradientBoostingClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        random_state=0\n",
    "    )\n",
    "    scores = cross_val_score(gb, X, y, cv=cvKFold)\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogR average cross-validation accuracy:  0.9385714285714284\n",
      "NB average cross-validation accuracy:  0.9264285714285714\n",
      "DT average cross-validation accuracy:  0.9178571428571429\n",
      "Bagging average cross-validation accuracy:  0.9400000000000001\n",
      "AdaBoost average cross-validation accuracy:  0.9328571428571429\n",
      "GB average cross-validation accuracy:  0.9299999999999999\n"
     ]
    }
   ],
   "source": [
    "# Parameters for Part 1:\n",
    "\n",
    "#NB\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "naive_score = nbClassifier(X, y)\n",
    "\n",
    "#Bagging\n",
    "bag_n_estimators = 50\n",
    "bag_max_samples = 100\n",
    "bag_max_depth = 5\n",
    "\n",
    "bag_score = bagDTClassifier(X, y, bag_n_estimators, bag_max_samples, bag_max_depth)\n",
    "\n",
    "#AdaBoost\n",
    "ada_n_estimators = 50\n",
    "ada_learning_rate = 0.5\n",
    "ada_bag_max_depth = 5\n",
    "\n",
    "ada_score = adaDTClassifier(X, y, ada_n_estimators, ada_learning_rate, ada_bag_max_depth)\n",
    "\n",
    "#GB\n",
    "gb_n_estimators = 50\n",
    "gb_learning_rate = 0.5\n",
    "\n",
    "gb_score = gbClassifier(X, y, gb_n_estimators, gb_learning_rate)\n",
    "\n",
    "#logR\n",
    "lr_mean = logregClassifier(X, y)\n",
    "\n",
    "#DT\n",
    "dt_mean = dtClassifier(X, y)\n",
    "\n",
    "# Print results for each classifier in part 1 to 4 decimal places here:\n",
    "print(\"LogR average cross-validation accuracy: \",lr_mean)\n",
    "print(\"NB average cross-validation accuracy: \",naive_score)\n",
    "print(\"DT average cross-validation accuracy: \",dt_mean)\n",
    "print(\"Bagging average cross-validation accuracy: \",bag_score)\n",
    "print(\"AdaBoost average cross-validation accuracy: \",ada_score)\n",
    "print(\"GB average cross-validation accuracy: \",gb_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Cross-validation with parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "k = [1, 3, 5, 7]\n",
    "p = [1, 2]\n",
    "\n",
    "def bestKNNClassifier(X, y):\n",
    "    # use global/public k and p defined above\n",
    "    param_grid = {'n_neighbors': k, 'p': p}\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=0, stratify=y\n",
    "    )\n",
    "\n",
    "    gs = GridSearchCV(KNeighborsClassifier(), param_grid,\n",
    "                      cv=10, scoring='accuracy')\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    best_k = gs.best_params_['n_neighbors']\n",
    "    best_p = gs.best_params_['p']\n",
    "    cv_acc = gs.best_score_\n",
    "\n",
    "    test_acc = accuracy_score(y_test, gs.best_estimator_.predict(X_test))\n",
    "\n",
    "    return best_k, best_p, cv_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "# You should use RandomForestClassifier from sklearn.ensemble with information gain and max_features set to ‘sqrt’.\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "n_estimators = [10, 30, 60, 100]\n",
    "max_leaf_nodes = [6, 12]\n",
    "\n",
    "def bestRFClassifier(X, y):\n",
    "# ===== Split data into train/test with stratification\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=0\n",
    "    )\n",
    "\n",
    "    # ====== Stratified 10-fold cross-validation\n",
    "    cvKFold = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "    # ===== Base Random Forest model \n",
    "    rf = RandomForestClassifier(\n",
    "        criterion=\"entropy\", # use information gain\n",
    "        max_features=\"sqrt\", # feature selection strategy\n",
    "        random_state=0,\n",
    "    )\n",
    "\n",
    "    # ====== Parameter grid \n",
    "    param_grid = {\n",
    "        \"n_estimators\": n_estimators,  \n",
    "        \"max_leaf_nodes\": max_leaf_nodes,   \n",
    "    }\n",
    "\n",
    "    # ===== Grid search with cross-validation \n",
    "    gscv = GridSearchCV(\n",
    "        estimator=rf,\n",
    "        param_grid=param_grid,\n",
    "        scoring=\"accuracy\",\n",
    "        cv=cvKFold,\n",
    "        n_jobs=1,      \n",
    "        refit=True,\n",
    "        return_train_score=False,\n",
    "    )\n",
    "    gscv.fit(X_train, y_train)\n",
    "\n",
    "    # ===== Get best model and CV score \n",
    "    best_model = gscv.best_estimator_\n",
    "    best_params = gscv.best_params_\n",
    "    best_cv_acc = float(gscv.best_score_)\n",
    "\n",
    "    # ====== Evaluate on the test set \n",
    "    y_pred = best_model.predict(X_test)\n",
    "    test_acc = float(accuracy_score(y_test, y_pred))\n",
    "    macro_f1 = float(f1_score(y_test, y_pred, average=\"macro\"))\n",
    "    weighted_f1 = float(f1_score(y_test, y_pred, average=\"weighted\"))\n",
    "\n",
    "    return (\n",
    "        int(best_params[\"n_estimators\"]),\n",
    "        int(best_params[\"max_leaf_nodes\"]),\n",
    "        best_cv_acc,\n",
    "        test_acc,\n",
    "        macro_f1,\n",
    "        weighted_f1\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN best k: 5\n",
      "KNN best p: 1\n",
      "KNN cross-validation accuracy: 0.9366071428571429\n",
      "KNN test set accuracy: 0.9214285714285714\n",
      "\n",
      "RF best n_estimators: 30\n",
      "RF best max_leaf_nodes: 6\n",
      "RF cross-validation accuracy: 0.9411\n",
      "RF test set accuracy: 0.9429\n",
      "RF test set macro average F1: 0.9414\n",
      "RF test set weighted average F1: 0.9427\n"
     ]
    }
   ],
   "source": [
    "# Perform Grid Search with 10-fold stratified cross-validation (GridSearchCV in sklearn). \n",
    "# The stratified folds from cvKFold should be provided to GridSearchV\n",
    "\n",
    "# This should include using train_test_split from sklearn.model_selection with stratification and random_state=0\n",
    "# Print results for each classifier here. All results should be printed to 4 decimal places except for\n",
    "# \"k\", \"p\", n_estimators\" and \"max_leaf_nodes\" which should be printed as integers.\n",
    "\n",
    "best_k, best_p, cv_score, test_score = bestKNNClassifier(X, y)\n",
    "\n",
    "print(\"KNN best k:\", best_k)\n",
    "print(\"KNN best p:\", best_p)\n",
    "print(\"KNN cross-validation accuracy:\", cv_score)\n",
    "print(\"KNN test set accuracy:\", test_score)\n",
    "\n",
    "print()\n",
    "\n",
    "best_n, best_leaf, cv_acc, tst_acc, macro_f1, weighted_f1 = bestRFClassifier(X, y)\n",
    "\n",
    "\n",
    "print(\"RF best n_estimators:\", best_n)\n",
    "print(\"RF best max_leaf_nodes:\", best_leaf)\n",
    "print(\"RF cross-validation accuracy:\", round(cv_acc, 4))\n",
    "print(\"RF test set accuracy:\", round(tst_acc, 4))\n",
    "print(\"RF test set macro average F1:\", round(macro_f1, 4))\n",
    "print(\"RF test set weighted average F1:\", round(weighted_f1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
